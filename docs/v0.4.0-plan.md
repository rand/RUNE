# RUNE v0.4.0 Architecture Plan

## Overview

Version 0.4.0 represents RUNE's transition to production readiness with Python bindings, HTTP server, and comprehensive observability. This release focuses on accessibility, remote operation, and production monitoring.

## Goals

1. **Python Bindings**: Native Python integration for AI/ML frameworks
2. **HTTP Server**: Remote authorization API
3. **Observability**: Prometheus metrics + OpenTelemetry tracing
4. **Test Coverage**: 85%+ coverage with property-based testing

## Architecture Components

### 1. Python Bindings (PyO3)

**Design Principles:**
- Zero-copy where possible using PyO3's memory sharing
- Async support with Python's asyncio
- Pythonic API that follows PEP conventions
- Type hints for IDE support

**Core API:**
```python
import rune

# Initialize engine
engine = rune.Engine()
engine.load_config("config.rune")

# Synchronous authorization
result = engine.authorize(
    principal="user:alice",
    action="read",
    resource="file:/tmp/data.txt"
)

# Async authorization
async def check_access():
    result = await engine.authorize_async(...)
    return result.decision == rune.Decision.PERMIT

# Decorator-based enforcement
@rune.enforce(action="execute", resource_type="function")
def sensitive_operation():
    pass

# Context manager for scoped rules
with engine.scoped_rules(additional_rules):
    result = engine.authorize(...)
```

**Implementation Tasks:**
1. Create `rune-python/src/lib.rs` with PyO3 module definition
2. Wrap core types: Request, Decision, AuthorizationResult
3. Implement Engine wrapper with GIL-safe operations
4. Add async support using pyo3-asyncio
5. Create Python type stubs (.pyi files)
6. Write comprehensive Python tests

### 2. HTTP Server

**Design Principles:**
- RESTful API following OpenAPI 3.0
- JWT authentication for API access
- Rate limiting per client
- Graceful shutdown with request draining

**API Endpoints:**
```yaml
# Authorization
POST /v1/authorize
  Body: { principal, action, resource, context }
  Response: { decision, reasons, diagnostics }

# Batch Authorization
POST /v1/authorize/batch
  Body: { requests: [...] }
  Response: { results: [...] }

# Configuration Management
GET  /v1/config
POST /v1/config/reload
GET  /v1/config/validate

# Health & Metrics
GET /health/live
GET /health/ready
GET /metrics  # Prometheus format
```

**Implementation Stack:**
- **Framework**: axum (fast, type-safe)
- **Async Runtime**: tokio (already in use)
- **Serialization**: serde_json
- **Authentication**: jsonwebtoken for JWT
- **Rate Limiting**: tower-governor
- **OpenAPI**: utoipa for auto-generation

**Implementation Tasks:**
1. Create `rune-server` crate
2. Define API types and routes
3. Implement authorization endpoints
4. Add JWT authentication middleware
5. Implement rate limiting
6. Add OpenAPI documentation
7. Create Docker container

### 3. Observability

#### Prometheus Metrics

**Key Metrics:**
```rust
// Counters
authorization_requests_total{decision="permit|deny"}
cache_hits_total
cache_misses_total
rule_evaluations_total
policy_evaluations_total
reload_events_total{result="success|failed"}

// Histograms
authorization_latency_seconds
datalog_evaluation_latency_seconds
cedar_evaluation_latency_seconds
cache_lookup_latency_seconds

// Gauges
loaded_rules_count
loaded_policies_count
cache_size_bytes
fact_store_entries
active_connections (HTTP server)
```

**Implementation:**
- Use `metrics` crate with `metrics-exporter-prometheus`
- Instrument all critical paths
- Export via HTTP `/metrics` endpoint

#### OpenTelemetry Tracing

**Trace Structure:**
```
authorize_request (root span)
├── parse_request
├── cache_lookup
├── datalog_evaluation
│   ├── fact_preparation
│   ├── rule_evaluation
│   └── result_extraction
├── cedar_evaluation
│   ├── entity_creation
│   └── policy_evaluation
├── combine_results
└── cache_update
```

**Implementation:**
- Use `tracing` with `tracing-opentelemetry`
- Support OTLP, Jaeger, and Zipkin exporters
- Configurable sampling (1%, 10%, 100%)
- Baggage propagation for request context

### 4. Comprehensive Testing

**Test Coverage Goals:**
- Core engine: 90%+
- HTTP server: 85%+
- Python bindings: 80%+
- Overall: 85%+

**Test Types:**

1. **Unit Tests** (existing + new):
   - All public APIs
   - Error paths
   - Edge cases

2. **Integration Tests**:
   - HTTP server endpoints
   - Python bindings
   - Hot-reload scenarios
   - Multi-threaded access

3. **Property-Based Tests** (new):
   ```rust
   use proptest::prelude::*;

   proptest! {
       #[test]
       fn authorization_deterministic(
           principal in any::<String>(),
           action in any::<String>(),
           resource in any::<String>()
       ) {
           // Same request should always return same result
           let result1 = engine.authorize(...);
           let result2 = engine.authorize(...);
           assert_eq!(result1, result2);
       }
   }
   ```

4. **Benchmarks** (criterion):
   - Micro-benchmarks for critical paths
   - Macro-benchmarks for end-to-end flows
   - Memory usage tracking

5. **Fuzzing** (optional):
   - Parser fuzzing with cargo-fuzz
   - API endpoint fuzzing

## Implementation Order

### Phase 1: HTTP Server (Week 1)
1. Create rune-server crate
2. Implement basic authorization endpoint
3. Add health checks
4. Create Docker container
5. Write integration tests

**Rationale**: HTTP server enables immediate remote usage and testing

### Phase 2: Observability (Week 1-2)
1. Add Prometheus metrics to core
2. Instrument HTTP server
3. Add OpenTelemetry tracing
4. Create Grafana dashboard
5. Document monitoring setup

**Rationale**: Observability needed before production deployment

### Phase 3: Python Bindings (Week 2-3)
1. Setup PyO3 in rune-python
2. Wrap core types
3. Implement sync API
4. Add async support
5. Create pip package
6. Write Python tests

**Rationale**: Python bindings enable AI/ML integration

### Phase 4: Test Coverage (Week 3-4)
1. Add missing unit tests
2. Write property-based tests
3. Create integration test suite
4. Setup code coverage CI
5. Document test strategy

**Rationale**: Comprehensive testing ensures production readiness

## Dependencies to Add

```toml
# Workspace dependencies
[workspace.dependencies]
# HTTP Server
axum = "0.7"
tower = "0.4"
tower-governor = "0.3"
tower-http = { version = "0.5", features = ["cors", "trace"] }
hyper = "1.0"
jsonwebtoken = "9.2"
utoipa = { version = "4.1", features = ["axum_extras"] }
utoipa-swagger-ui = { version = "6.0", features = ["axum"] }

# Observability
tracing-opentelemetry = "0.22"
opentelemetry = "0.21"
opentelemetry-otlp = "0.14"

# Testing
proptest = "1.4"
criterion = { version = "0.5", features = ["html_reports"] }
cargo-fuzz = "0.12"  # Dev dependency

# Python (in rune-python/Cargo.toml)
pyo3 = { version = "0.20", features = ["extension-module", "abi3-py39"] }
pyo3-asyncio = { version = "0.20", features = ["tokio-runtime"] }
```

## Success Criteria

1. **HTTP Server**:
   - [ ] All endpoints return < 10ms P99
   - [ ] Handles 10K+ RPS on single core
   - [ ] OpenAPI docs auto-generated
   - [ ] Docker image < 50MB

2. **Python Bindings**:
   - [ ] Zero-copy for large data
   - [ ] Type hints work in IDEs
   - [ ] Published to PyPI
   - [ ] Works with Python 3.9+

3. **Observability**:
   - [ ] All critical paths instrumented
   - [ ] Grafana dashboard included
   - [ ] Trace sampling configurable
   - [ ] Metrics cardinality < 1000

4. **Testing**:
   - [ ] 85%+ code coverage
   - [ ] All benchmarks pass
   - [ ] CI runs in < 5 minutes
   - [ ] Property tests for invariants

## Risks & Mitigations

1. **PyO3 Complexity**:
   - Risk: GIL interactions, memory safety
   - Mitigation: Extensive testing, follow PyO3 best practices

2. **HTTP Performance**:
   - Risk: Serialization overhead
   - Mitigation: Use zero-copy where possible, batch endpoints

3. **Metric Cardinality**:
   - Risk: Too many label combinations
   - Mitigation: Limit labels, use recording rules

4. **Test Flakiness**:
   - Risk: Timing-dependent tests
   - Mitigation: Use deterministic testing, proper mocking

## Documentation Updates

1. **README.md**: Add HTTP server quickstart, Python examples
2. **API.md**: Full HTTP API documentation
3. **PYTHON.md**: Python bindings guide
4. **MONITORING.md**: Observability setup guide
5. **TESTING.md**: Test strategy and coverage reports

## Version Bump

After implementation:
- Version: 0.3.0 → 0.4.0
- Update CHANGELOG.md
- Create GitHub release
- Publish to crates.io
- Publish to PyPI

---

**Estimated Timeline**: 3-4 weeks
**Priority**: HTTP Server → Observability → Python → Testing
**Next Steps**: Begin with HTTP server implementation